{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khawar-khan520/nlp_project/blob/main/retrieval_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "445f2f8a",
      "metadata": {
        "id": "445f2f8a"
      },
      "source": [
        "Install and Import Libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71010369",
      "metadata": {
        "id": "71010369"
      },
      "outputs": [],
      "source": [
        "!pip install openai sentence-transformers faiss-cpu hf_xet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "0i1mtswJGwfe"
      },
      "id": "0i1mtswJGwfe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "21deb282",
      "metadata": {
        "id": "21deb282"
      },
      "source": [
        "Load and Chunk your Document:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d40d6da7",
      "metadata": {
        "id": "d40d6da7"
      },
      "outputs": [],
      "source": [
        "\n",
        "with open('winnie_the_pooh.txt', 'r') as file:\n",
        "    # Read the entire content of the file into a string\n",
        "    text = file.read()\n",
        "\n",
        "chunks = [text[i:i+200] for i in range(0, len(text), 200)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f06cd075",
      "metadata": {
        "id": "f06cd075"
      },
      "source": [
        "Generate Embeddings with SenteceTransformers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64f757a9",
      "metadata": {
        "id": "64f757a9"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "embeddings = model.encode(chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22a935f0",
      "metadata": {
        "id": "22a935f0"
      },
      "source": [
        "Store Embeddings in a FAISS Index for Similarity Search:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5655044b",
      "metadata": {
        "id": "5655044b"
      },
      "outputs": [],
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "index = faiss.IndexFlatL2(embeddings[0].shape[0])\n",
        "index.add(np.array(embeddings))\n",
        "\n",
        "# Search\n",
        "query = \"Who is always sad?\"\n",
        "query_embedding = model.encode([query])\n",
        "D, I = index.search(np.array(query_embedding), k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49880ec2",
      "metadata": {
        "id": "49880ec2"
      },
      "outputs": [],
      "source": [
        "for i in I[0]:\n",
        "    print(chunks[i])\n",
        "    print(\"....\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88a86dc2",
      "metadata": {
        "id": "88a86dc2"
      },
      "source": [
        "Build the Prompt from Retrieved Chunks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebce8464",
      "metadata": {
        "id": "ebce8464"
      },
      "outputs": [],
      "source": [
        "\n",
        "retrieved_chunks = [chunks[i] for i in I[0]]\n",
        "\n",
        "# Format the prompt\n",
        "context = \"\\n\\n\".join(retrieved_chunks)\n",
        "#query = \"What is the capital of France?\"\n",
        "\n",
        "prompt = f\"\"\"You are a helpful assistant. Use the following context to answer the question.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{query}\n",
        "\n",
        "Answer:\"\"\"\n",
        "\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50b06930",
      "metadata": {
        "id": "50b06930"
      },
      "source": [
        "Generate an Answer Using a Lightweight Language Model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4f117f4",
      "metadata": {
        "id": "d4f117f4"
      },
      "outputs": [],
      "source": [
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "import torch\n",
        "\n",
        "# Load a small, instruction-tuned model\n",
        "model_name = \"google/flan-t5-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n",
        "# Build prompt from chunks\n",
        "retrieved_chunks = [chunks[i] for i in I[0]]\n",
        "context = \"\\n\\n\".join(retrieved_chunks)\n",
        "\n",
        "\n",
        "# Simple instruction-style prompt for T5\n",
        "prompt = f\"Answer the question based on the context.\\n\\nContext:\\n{context}\\n\\nQuestion:\\n{query}\"\n",
        "\n",
        "# Tokenize input\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True)\n",
        "\n",
        "# Generate output\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(**inputs, max_new_tokens=100)\n",
        "\n",
        "# Decode and print\n",
        "answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(\"Answer:\", answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2: Retriever Class with FAISS\""
      ],
      "metadata": {
        "id": "FMexSkPDEwQS"
      },
      "id": "FMexSkPDEwQS"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence-transformers faiss-cpu\n"
      ],
      "metadata": {
        "id": "PFnbAvf0B2Ij"
      },
      "id": "PFnbAvf0B2Ij",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "class Retriever:\n",
        "    def __init__(self, model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "        self.index = None\n",
        "        self.documents = []\n",
        "        self.embeddings = None\n",
        "\n",
        "    def chunk_text(self, text, chunk_size=200, overlap=50):\n",
        "        chunks = []\n",
        "        for i in range(0, len(text), chunk_size - overlap):\n",
        "            chunk = text[i:i + chunk_size]\n",
        "            chunks.append(chunk)\n",
        "        return chunks\n",
        "\n",
        "    def add_documents(self, texts):\n",
        "        chunks = []\n",
        "        for text in texts:\n",
        "            chunks.extend(self.chunk_text(text))\n",
        "        self.documents.extend(chunks)\n",
        "        embeddings = self.model.encode(chunks, show_progress_bar=True)\n",
        "        self.embeddings = np.array(embeddings).astype(\"float32\")\n",
        "        self.index = faiss.IndexFlatL2(self.embeddings.shape[1])\n",
        "        self.index.add(self.embeddings)\n",
        "\n",
        "    def query(self, question, top_k=3):\n",
        "        query_embedding = self.model.encode([question]).astype(\"float32\")\n",
        "        D, I = self.index.search(query_embedding, top_k)\n",
        "        return [self.documents[i] for i in I[0]]\n",
        "\n",
        "    def save(self, path=\"retriever_data\"):\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "        faiss.write_index(self.index, os.path.join(path, \"index.faiss\"))\n",
        "        with open(os.path.join(path, \"documents.pkl\"), \"wb\") as f:\n",
        "            pickle.dump(self.documents, f)\n",
        "\n",
        "    def load(self, path=\"retriever_data\"):\n",
        "        self.index = faiss.read_index(os.path.join(path, \"index.faiss\"))\n",
        "        with open(os.path.join(path, \"documents.pkl\"), \"rb\") as f:\n",
        "            self.documents = pickle.load(f)\n",
        "\n"
      ],
      "metadata": {
        "id": "c6WQ1_tNCFJq"
      },
      "id": "c6WQ1_tNCFJq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_txt(filepath):\n",
        "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
        "        return f.read()\n",
        "\n"
      ],
      "metadata": {
        "id": "06xUcDvTDa9w"
      },
      "id": "06xUcDvTDa9w",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = load_txt(\"winnie_the_pooh.txt\")\n",
        "retriever = Retriever()\n",
        "retriever.add_documents([text])\n"
      ],
      "metadata": {
        "id": "IoMsdA3mEHX7"
      },
      "id": "IoMsdA3mEHX7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is the main idea of the document?\"\n",
        "results = retriever.query(query)\n",
        "for i, r in enumerate(results, 1):\n",
        "    print(f\"Result {i}:\\n{r}\\n\")\n"
      ],
      "metadata": {
        "id": "PulBFkaIHSJo"
      },
      "id": "PulBFkaIHSJo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.save(\"my_retriever\")\n",
        "retriever.load(\"my_retriever\")\n"
      ],
      "metadata": {
        "id": "IRdUVdJeEKB2"
      },
      "id": "IRdUVdJeEKB2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_retriever():\n",
        "    doc = \"This is a test document about AI and NLP.\"\n",
        "    retriever = Retriever()\n",
        "    retriever.add_documents([doc])\n",
        "    result = retriever.query(\"What is it about?\")\n",
        "    assert \"AI and NLP\" in result[0]\n",
        "\n",
        "test_retriever()\n"
      ],
      "metadata": {
        "id": "zRxBJt-dHlIE"
      },
      "id": "zRxBJt-dHlIE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"retriever.py\", \"w\") as f:\n",
        "    f.write(\"\"\"\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "class Retriever:\n",
        "    def __init__(self, model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "        self.index = None\n",
        "        self.documents = []\n",
        "        self.embeddings = None\n",
        "\n",
        "    def chunk_text(self, text, chunk_size=200, overlap=50):\n",
        "        chunks = []\n",
        "        for i in range(0, len(text), chunk_size - overlap):\n",
        "            chunk = text[i:i + chunk_size]\n",
        "            chunks.append(chunk)\n",
        "        return chunks\n",
        "\n",
        "    def add_documents(self, texts):\n",
        "        chunks = []\n",
        "        for text in texts:\n",
        "            chunks.extend(self.chunk_text(text))\n",
        "        self.documents.extend(chunks)\n",
        "        embeddings = self.model.encode(chunks, show_progress_bar=True)\n",
        "        self.embeddings = np.array(embeddings).astype(\"float32\")\n",
        "        self.index = faiss.IndexFlatL2(self.embeddings.shape[1])\n",
        "        self.index.add(self.embeddings)\n",
        "\n",
        "    def query(self, question, top_k=3):\n",
        "        query_embedding = self.model.encode([question]).astype(\"float32\")\n",
        "        D, I = self.index.search(query_embedding, top_k)\n",
        "        return [self.documents[i] for i in I[0]]\n",
        "\n",
        "    def save(self, path=\"retriever_data\"):\n",
        "        os.makedirs(path, exist_ok=True)\n",
        "        faiss.write_index(self.index, os.path.join(path, \"index.faiss\"))\n",
        "        with open(os.path.join(path, \"documents.pkl\"), \"wb\") as f:\n",
        "            pickle.dump(self.documents, f)\n",
        "\n",
        "    def load(self, path=\"retriever_data\"):\n",
        "        self.index = faiss.read_index(os.path.join(path, \"index.faiss\"))\n",
        "        with open(os.path.join(path, \"documents.pkl\"), \"rb\") as f:\n",
        "            self.documents = pickle.load(f)\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "BHMgehTbESNn"
      },
      "id": "BHMgehTbESNn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.save()  # Saves to folder\n",
        "retriever.load()  # Loads from saved folder\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "00Ep9FfkMNkl"
      },
      "id": "00Ep9FfkMNkl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_retriever():\n",
        "    doc = \"This is a test document about AI and NLP.\"\n",
        "    retriever = Retriever()\n",
        "    retriever.add_documents([doc])\n",
        "    result = retriever.query(\"What is it about?\")\n",
        "    assert \"AI and NLP\" in result[0]\n",
        "\n",
        "test_retriever()\n"
      ],
      "metadata": {
        "id": "YZzVutJLNhwN"
      },
      "id": "YZzVutJLNhwN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"retriever.py\")  # Download retriever.py, or any other files\n",
        "\n"
      ],
      "metadata": {
        "id": "DtGo8LC2TLKd"
      },
      "id": "DtGo8LC2TLKd",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}